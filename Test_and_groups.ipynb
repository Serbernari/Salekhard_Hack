{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hleb_test_to_vec(user_json):\n",
    "    hleb_df = pd.DataFrame.from_dict(data, orient='index',  columns=[\"Переведёте ли вы бабушку через дорогу?\",\"Что бы вы сказали другу если бы он попросил принести вас таблетки?\",\"Посадили ли бы вы у себя во дворе дерево/кустарник?\",\"Любите наблюдать за спортивными играми/соревнованиями?\",\"Разбираетесь ли вы в компьютерных играх?\",\"Насколько вы любите посещать общественные мероприятия?\",\"Спасли бы вы котёнка с дерева?\",\"Необходима ли культура человеку?\",\"Интересна ли вам история?\",\"Готовы ли вы часами пробираться сквозь бурелом ради спасения человека?\"])\n",
    "    hleb_df = hleb_df['test']\n",
    "    hleb_df = hleb_df.replace({\"Да, обязательно\": 3,\"Да, если не очень занят(а)\": 2,\\\n",
    "                \"Нет, если вижу что она скорее всего справится сама\":1,\\\n",
    "                \"Могу перевести только на английский\":0})\n",
    "    hleb_df = hleb_df.replace({\"Соглашусь, даже если очень занят\": 3,'Только легальные и из аптеки, а не там около трубы закопаны': 2,\\\n",
    "                    \"Соглашусь, если больше совсем уж некому\":1,\\\n",
    "                    \"Почему бы не сходить самому или не вызвать скорую?\":0})\n",
    "    hleb_df = hleb_df.replace({\"Да, озеленение это круто. Надеюсь переживет 9 месяцев Ямальской зимы.\": 3,\"Если мне дадут саженцы - почему нет?\": 2,\\\n",
    "                    \"Скорее нет чем да\":1,\\\n",
    "                    \"Для этого есть специализированные службы, которые лучше справятся\":0})\n",
    "    hleb_df = hleb_df.replace({\"Да, и сам люблю участвовать в них\": 3,\"Да, это потрясающий эмоциональный аттракцион\": 2,\\\n",
    "                    \"Только скоростное вязание крючком\":1,\\\n",
    "                    \"Нет, мне это не интересно\":0})\n",
    "    hleb_df[\"Разбираетесь ли вы в компьютерных играх?\"] = \\\n",
    "    hleb_df[\"Разбираетесь ли вы в компьютерных играх?\"].replace({\"GG EZ\": 3,\"Играю, но не слежу за киберспортивной сценой\": 2,\\\n",
    "                    \"Играю только в змейку на телефоне\":1,\\\n",
    "                    \"...что за фигня написана в первом варианте ответа?\":0})\n",
    "    hleb_df = hleb_df.replace({\"Любая движуха это круто!\": 3,\"Только действительно интересные\": 2,\\\n",
    "                    \"Ну, вероятно пара-тройка мероприятий стоит моего внимания\":1,\\\n",
    "                    \"На ютюбе запись посмотрю\":0})\n",
    "    hleb_df = hleb_df.replace({\"Я спасу кота, выполню приказ\": 3,\"Только если топор дадите\": 2,\\\n",
    "                    \"Ну если мне уж совсем делать нечего\":1,\\\n",
    "                    \"Устанет - слезет\":0})\n",
    "    hleb_df = hleb_df.replace({\"Да, это то что делает нас людьми\": 3,\"Ну, без пищи для ума прожить, конечно можно, но не так интересо\": 2,\\\n",
    "                    \"Не всем и не всегда\":1,\\\n",
    "                    \"GG EZ\":0})\n",
    "    hleb_df = hleb_df.replace({\"Да, не помня прошлого мы обречены на его повторение\": 3,\"Скорее да чем нет\": 2,\\\n",
    "                    \"Только без часовых лекций, пожалуйста\":1,\\\n",
    "                    \"Жить надо настоящим\":0})\n",
    "    hleb_df = hleb_df.replace({\"Да, буду идти пока сам(а) не упаду\": 3,\"Если это близкий мне человек - то разумеется\": 2,\\\n",
    "                    \"Я думаю принесу больше пользы своим умом а не ногами\":1,\\\n",
    "                    \"Для этого есть МЧС и они прекрасно справятся\":0})\n",
    "    hleb_df = hleb_df.rename(columns={\"Переведёте ли вы бабушку через дорогу?\": \"social\",\\\n",
    "                         \"Что бы вы сказали другу если бы он попросил принести вас таблетки? \": \"med\",\\\n",
    "                         \"Посадили ли бы вы у себя во дворе дерево/кустарник?\": \"eco\",\\\n",
    "                         \"Любите наблюдать за спортивными играми/соревнованиями?\": \"sport\",\\\n",
    "                         \"Разбираетесь ли вы в компьютерных играх?\": \"cyber\",\\\n",
    "                         \"Насколько вы любите посещать общественные мероприятия?\": \"events\",\\\n",
    "                         \"Спасли бы вы котёнка с дерева?\": \"animals\",\\\n",
    "                         \"Необходима ли культура человеку?\": \"culture\",\\\n",
    "                         \"Интересна ли вам история?\": \"ww2\",\\\n",
    "                        \"Готовы ли вы часами пробираться сквозь бурелом ради спасения человека?\": \"search\"})\n",
    "    return hleb_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#возвращает вектор заинтересованности волонтера по его группам вк\n",
    "def groups_to_dict (user_json):\n",
    " \n",
    "    user_groups = []\n",
    "    for i in range(len(user_json['groups'])):\n",
    "        user_groups.append(user_json['groups'][i])\n",
    "    \n",
    "    events = {'name': 'events', \n",
    "              'words': ['Товары для праздников','Тренинг, семинар',\\\n",
    "                        'Шоу, передача',\\\n",
    "                        'Школа','Цветы','Хостел','Фотограф','Фото- и видеосъёмка',\\\n",
    "                        'Фестиваль','Объявления', 'Культура, искусство','Культурный центр'\\\n",
    "                       'Музей, галерея, выставка','Организация праздников','Кинотеатр'\\\n",
    "                       'Концертный зал','Ночной клуб','Торгово-развлекательный центр',\\\n",
    "                       'Фестиваль','Цирк','Бар, паб']}\n",
    "    culture = {'name': 'culture', \n",
    "               'words': ['Литература','Товары для творчества','Туристическое агентство',\\\n",
    "                         'Туры, экскурсии','Компьютеры', 'Компьютерные игры',\\\n",
    "                         'Школа','Цирк','Цветы','Книга','Художник / Художница','Фильм',\\\n",
    "                        'Творчество','Кино','Искусство и развлечения']}\n",
    "    sport = {'name': 'sport', \n",
    "             'words': ['Спорт','Велосипеды','Водный транспорт','Школа','Хоккейная команда',\\\n",
    "                       'Футбольная команда','Фото- и видеосъёмка','Фитнес-центр',\\\n",
    "                       'Летние виды спорта', 'Спортивная команда', 'Спортивная организация'\\\n",
    "                       ,'Спортивное питание','Спортивный клуб','Спортивный комплекс',\\\n",
    "                       'Спортсмен / Спортсменка','Здоровый образ жизни','Хоккей', 'Футбол']}\n",
    "    med = {'name': 'med', \n",
    "           'words': ['Медицина','Аптека, оптика','Больница','Косметология',\\\n",
    "                     'Лекарственный препарат','Медицинская услуга','Медицинский центр',\\\n",
    "                      'Стоматология']}\n",
    "    ww2 = {'name': 'ww2', \n",
    "           'words': ['Архив','Библиотека','Дом культуры','Антиквариат','Пенсионный фонд','История',\\\n",
    "                    'Военное дело']}\n",
    "    cyber = {'name': 'cyber', \n",
    "             'words': ['Компьютерная техника','Киберспортивная команда',\\\n",
    "                    'Киберспортивная организация', 'Киберспортсмен',\\\n",
    "                      'Компьютеры', 'Компьютерные игры','Видеоигра','Стример','Киберспорт']}\n",
    "    social = {'name': 'social', \n",
    "              'words': ['Молодёжное движение','Торговый центр','Тренинг, семинар','Управляющая компания',\\\n",
    "                        'Юридические услуги',\\\n",
    "                        'Химчистка, прачечная','Финансы и страхование','Финансовые рынки',\\\n",
    "                       'Дискуссионный клуб','Общество','Благотворительная организация']}\n",
    "    eco = {'name': 'eco', \n",
    "           'words': ['Туризм и отдых','Активный отдых','Визовый центр','Гостиница',\\\n",
    "             'Информационный портал','Летний лагерь','Национальный парк, заповедник','Охота и рыбалка',\\\n",
    "             'Продажа билетов, бронирование гостиниц','Санаторий, дом отдыха','Туристическое агентство',\\\n",
    "             'Туры, экскурсии','Хостел']}\n",
    "    animals = {'name': 'animals', \n",
    "               'words': ['Животные','Ветеринарная клиника','Зоомагазин',\\\n",
    "                         'Товары для животных','Услуги для владельцев животных','Домашние и дикие животные']}\n",
    "    search = {'name': 'search', \n",
    "              'words': ['Благотворительная организация','Туризм и отдых','Активный отдых',\\\n",
    "                'Национальный парк, заповедник','Охота и рыбалка','Здоровый образ жизни']}\n",
    "    \n",
    "    competences = [events, culture, sport, med, ww2, cyber, social, eco, animals, search]\n",
    "   \n",
    "    user_vec = {elem['name']:0 for elem in competences}\n",
    "       \n",
    "\n",
    "   #собираем сырой вектор, не нормализированный\n",
    "    for comp in competences:\n",
    "        for key_word in comp['words']:\n",
    "            if key_word in user_groups:\n",
    "                user_vec[comp['name']] = user_groups.count(key_word)\n",
    "#     стандартизуем вектор к 0..1\n",
    "#     a = np.fromiter(user_vec.values(), dtype=float)\n",
    "#     minval = np.min(a)\n",
    "#     maxval = np.max(a[np.nonzero(a)])\n",
    "\n",
    "#     if (maxval - minval != 0):\n",
    "#         for key in user_vec:\n",
    "#             if user_vec[key] != 0:\n",
    "#                 user_vec[key] -= minval\n",
    "#                 user_vec[key] /= (maxval - minval)\n",
    "#                 user_vec[key] *= 10\n",
    "#                 user_vec[key] = int(user_vec[key])\n",
    "  \n",
    "    \n",
    "    return user_vec\n",
    "   \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cathegory(input_json):\n",
    "    groups_to_dict(input_json)\n",
    "    hleb_test_to_vec(input_json)\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with open('test.json', encoding='utf-8', errors = 'ignore') as json_file:\n",
    "    data = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "10 columns passed, passed data had 2 columns",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-40-4457464772bb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mhleb_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morient\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'index'\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"Переведёте ли вы бабушку через дорогу?\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"Что бы вы сказали другу если бы он попросил принести вас таблетки?\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"Посадили ли бы вы у себя во дворе дерево/кустарник?\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"Любите наблюдать за спортивными играми/соревнованиями?\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"Разбираетесь ли вы в компьютерных играх?\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"Насколько вы любите посещать общественные мероприятия?\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"Спасли бы вы котёнка с дерева?\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"Необходима ли культура человеку?\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"Интересна ли вам история?\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"Готовы ли вы часами пробираться сквозь бурелом ради спасения человека?\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mhleb_df\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\deep_learning\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mfrom_dict\u001b[1;34m(cls, data, orient, dtype, columns)\u001b[0m\n\u001b[0;32m   1136\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'only recognize index or columns for orient'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1137\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1138\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1139\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1140\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mto_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\deep_learning\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    433\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[0mis_named_tuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mcolumns\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    434\u001b[0m                         \u001b[0mcolumns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fields\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 435\u001b[1;33m                     \u001b[0marrays\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_arrays\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    436\u001b[0m                     \u001b[0mcolumns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mensure_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    437\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\deep_learning\\lib\\site-packages\\pandas\\core\\internals\\construction.py\u001b[0m in \u001b[0;36mto_arrays\u001b[1;34m(data, columns, coerce_float, dtype)\u001b[0m\n\u001b[0;32m    402\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    403\u001b[0m         return _list_to_arrays(data, columns, coerce_float=coerce_float,\n\u001b[1;32m--> 404\u001b[1;33m                                dtype=dtype)\n\u001b[0m\u001b[0;32m    405\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMapping\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    406\u001b[0m         return _list_of_dict_to_arrays(data, columns,\n",
      "\u001b[1;32m~\\.conda\\envs\\deep_learning\\lib\\site-packages\\pandas\\core\\internals\\construction.py\u001b[0m in \u001b[0;36m_list_to_arrays\u001b[1;34m(data, columns, coerce_float, dtype)\u001b[0m\n\u001b[0;32m    434\u001b[0m         \u001b[0mcontent\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_object_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    435\u001b[0m     return _convert_object_array(content, columns, dtype=dtype,\n\u001b[1;32m--> 436\u001b[1;33m                                  coerce_float=coerce_float)\n\u001b[0m\u001b[0;32m    437\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    438\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\deep_learning\\lib\\site-packages\\pandas\\core\\internals\\construction.py\u001b[0m in \u001b[0;36m_convert_object_array\u001b[1;34m(content, columns, coerce_float, dtype)\u001b[0m\n\u001b[0;32m    490\u001b[0m             raise AssertionError('{col:d} columns passed, passed data had '\n\u001b[0;32m    491\u001b[0m                                  '{con} columns'.format(col=len(columns),\n\u001b[1;32m--> 492\u001b[1;33m                                                         con=len(content)))\n\u001b[0m\u001b[0;32m    493\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    494\u001b[0m     \u001b[1;31m# provide soft conversion of object dtypes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAssertionError\u001b[0m: 10 columns passed, passed data had 2 columns"
     ]
    }
   ],
   "source": [
    "hleb_df = pd.DataFrame.from_dict(data, orient='index',  columns=[\"Переведёте ли вы бабушку через дорогу?\",\"Что бы вы сказали другу если бы он попросил принести вас таблетки?\",\"Посадили ли бы вы у себя во дворе дерево/кустарник?\",\"Любите наблюдать за спортивными играми/соревнованиями?\",\"Разбираетесь ли вы в компьютерных играх?\",\"Насколько вы любите посещать общественные мероприятия?\",\"Спасли бы вы котёнка с дерева?\",\"Необходима ли культура человеку?\",\"Интересна ли вам история?\",\"Готовы ли вы часами пробираться сквозь бурелом ради спасения человека?\"])\n",
    "hleb_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "10 columns passed, passed data had 2 columns",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-41-008c043bc6f5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mget_cathegory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-38-cfc79a85444d>\u001b[0m in \u001b[0;36mget_cathegory\u001b[1;34m(input_json)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mget_cathegory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_json\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mgroups_to_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_json\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mhleb_test_to_vec\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_json\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-36-f524865a84fb>\u001b[0m in \u001b[0;36mhleb_test_to_vec\u001b[1;34m(user_json)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mhleb_test_to_vec\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muser_json\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mhleb_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morient\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'index'\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"Переведёте ли вы бабушку через дорогу?\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"Что бы вы сказали другу если бы он попросил принести вас таблетки?\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"Посадили ли бы вы у себя во дворе дерево/кустарник?\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"Любите наблюдать за спортивными играми/соревнованиями?\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"Разбираетесь ли вы в компьютерных играх?\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"Насколько вы любите посещать общественные мероприятия?\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"Спасли бы вы котёнка с дерева?\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"Необходима ли культура человеку?\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"Интересна ли вам история?\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"Готовы ли вы часами пробираться сквозь бурелом ради спасения человека?\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[0mhleb_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhleb_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'test'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     hleb_df = hleb_df.replace({\"Да, обязательно\": 3,\"Да, если не очень занят(а)\": 2,\\\n\u001b[0;32m      5\u001b[0m                 \u001b[1;34m\"Нет, если вижу что она скорее всего справится сама\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\deep_learning\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mfrom_dict\u001b[1;34m(cls, data, orient, dtype, columns)\u001b[0m\n\u001b[0;32m   1136\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'only recognize index or columns for orient'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1137\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1138\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1139\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1140\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mto_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\deep_learning\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    433\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[0mis_named_tuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mcolumns\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    434\u001b[0m                         \u001b[0mcolumns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fields\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 435\u001b[1;33m                     \u001b[0marrays\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_arrays\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    436\u001b[0m                     \u001b[0mcolumns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mensure_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    437\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\deep_learning\\lib\\site-packages\\pandas\\core\\internals\\construction.py\u001b[0m in \u001b[0;36mto_arrays\u001b[1;34m(data, columns, coerce_float, dtype)\u001b[0m\n\u001b[0;32m    402\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    403\u001b[0m         return _list_to_arrays(data, columns, coerce_float=coerce_float,\n\u001b[1;32m--> 404\u001b[1;33m                                dtype=dtype)\n\u001b[0m\u001b[0;32m    405\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMapping\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    406\u001b[0m         return _list_of_dict_to_arrays(data, columns,\n",
      "\u001b[1;32m~\\.conda\\envs\\deep_learning\\lib\\site-packages\\pandas\\core\\internals\\construction.py\u001b[0m in \u001b[0;36m_list_to_arrays\u001b[1;34m(data, columns, coerce_float, dtype)\u001b[0m\n\u001b[0;32m    434\u001b[0m         \u001b[0mcontent\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_object_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    435\u001b[0m     return _convert_object_array(content, columns, dtype=dtype,\n\u001b[1;32m--> 436\u001b[1;33m                                  coerce_float=coerce_float)\n\u001b[0m\u001b[0;32m    437\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    438\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\deep_learning\\lib\\site-packages\\pandas\\core\\internals\\construction.py\u001b[0m in \u001b[0;36m_convert_object_array\u001b[1;34m(content, columns, coerce_float, dtype)\u001b[0m\n\u001b[0;32m    490\u001b[0m             raise AssertionError('{col:d} columns passed, passed data had '\n\u001b[0;32m    491\u001b[0m                                  '{con} columns'.format(col=len(columns),\n\u001b[1;32m--> 492\u001b[1;33m                                                         con=len(content)))\n\u001b[0m\u001b[0;32m    493\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    494\u001b[0m     \u001b[1;31m# provide soft conversion of object dtypes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAssertionError\u001b[0m: 10 columns passed, passed data had 2 columns"
     ]
    }
   ],
   "source": [
    "get_cathegory(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
